{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assintment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EluXpNZpW7fH"
      },
      "outputs": [],
      "source": [
        "!pip install -q snscrape==0.3.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import date\n",
        "from random import uniform\n",
        "start = time.time()"
      ],
      "metadata": {
        "id": "nWbEcbglXd80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = date.today()\n",
        "end_date = today\n",
        "print(end_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuHtjkiHXstB",
        "outputId": "3a14469a-1037-47a4-8a81-4980c928c86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_term = ['aap','bsp','bjp','sp','congress']\n",
        "from_date = '2021-01-01' \n",
        "max_results = 1000"
      ],
      "metadata": {
        "id": "Dl_a02utapPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Number of Tweets for Search Terms Extracting"
      ],
      "metadata": {
        "id": "gqXWyYxiax34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "def Extract_tweets(search_term):\n",
        "  '''\n",
        "     Extracting Tweets from Twitter and create 5 file of Every Element of List\n",
        "  '''\n",
        "  os.system(\"snscrape --format '{content!r}'\"+ f\" --max-results {max_results} --since {from_date} twitter-search '{search_term} until:{end_date}' > {search_term}.txt\")\n",
        "\n",
        "for i in range(len(search_term)):\n",
        "  Extract_tweets(search_term[i])\n",
        "  \n",
        "print('\\n', f'Time: {time.time() - start}')"
      ],
      "metadata": {
        "id": "Hmi8-C3dbwjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7233b25-c18a-4f4c-fdc8-60e947541b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Time: 126.1495714187622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge All 5 txt Extracted  Tweets file"
      ],
      "metadata": {
        "id": "7Ezk7GgkhyRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "text_files=['aap.txt','bjp.txt','bsp.txt','congress.txt','sp.txt']\n",
        "def merge_text_files(text_files):\n",
        "  '''\n",
        "    Merge all 5 Txt Extracted File\n",
        "  '''\n",
        "  with open('merge_file.txt', 'w') as outfile:\n",
        "    for i in text_files:\n",
        "      with open(i) as infile:\n",
        "        for line in infile:\n",
        "          outfile.write(line)\n",
        "merge_text_files(text_files)\n",
        "\n",
        "print('\\n', f'Time: {time.time() - start}')"
      ],
      "metadata": {
        "id": "xwtNbSBvF7xE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbefaeb-bf7f-431e-e3d2-e388b7e175b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Time: 0.011391878128051758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"merge_file.txt\", header=None, \n",
        "                 names=[\"Text\"])\n"
      ],
      "metadata": {
        "id": "lxCa2WWRRotX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Merge .txt File To .csv "
      ],
      "metadata": {
        "id": "Ague3ZMQapib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"merge_file.csv\")"
      ],
      "metadata": {
        "id": "WKJmtvjKRo33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "5lESx0pRUjUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c119c428-e67f-4a64-b951-3d935ada96b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aefWEiQTUjec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}